{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from Function_list import genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_webcraw(url):\n",
    "    response = requests.get(url)\n",
    "    res = BeautifulSoup(response.text) # 預設html.parser，不打也相同\n",
    "    latest_data = res.find_all('div', class_ = 'download-item')[-1].a['href']\n",
    "    return latest_data\n",
    "url = 'https://data.gov.tw/dataset/59820'\n",
    "response = requests.get(url)\n",
    "res = BeautifulSoup(response.text)\n",
    "dataset_lst = res.find_all('div', class_ = 'download-item')\n",
    "dataset_eachfile = {}\n",
    "data_df = {}\n",
    "for i in dataset_lst:\n",
    "    title = i.text.split('\\n')[-1].strip()\n",
    "    downlaodLink = i.a['href']\n",
    "    dataset_eachfile[title] = downlaodLink\n",
    "    data_df[title] = pd.read_csv(downlaodLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = data_df['109年電影片分級及相關資訊']\n",
    "k[k['國別'].str.contains('美國')]\n",
    "# k[k['語言'] == 'Unknown']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "# 最後兩年有欄數不同與缺失\n",
    "for v in data_df.values():\n",
    "    print(v.isnull().sum().sum(), len(v.columns), sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演出時間有缺 但應該不需要這欄\n",
    "data_df['111年電影片分級及相關資訊'][data_df['111年電影片分級及相關資訊'].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理104~109 欄位未分割問題\n",
    "for title,m  in data_df.items():\n",
    "    try:\n",
    "        m['年度'] = m['年度'] + 1911\n",
    "        m['中文片名'] = m['中文片名/外文片名'].apply(lambda row : row.split('\\n')[0])\n",
    "        m['原文片名'] = m['中文片名/外文片名'].apply(lambda row : row.split('\\n')[1] if len(row.split('\\n')) > 1 else 'No Eng Name')\n",
    "        m['國別'] = m['國別/語別'].apply(lambda row : row.split('\\n')[0])\n",
    "        m['語言'] = m['國別/語別'].apply(lambda row : row.split('\\n')[1] if len(row.split('\\n')) > 1 else 'Unknown')\n",
    "        df = m[['年度', '中文片名', '原文片名', '國別', '語言']]\n",
    "        data_df[title] = df.drop_duplicates()\n",
    "    except KeyError:\n",
    "        df = m[['年度', '中文片名', '原文片名', '國別', '語言']]\n",
    "        data_df[title] = df.drop_duplicates()\n",
    "\n",
    "# check\n",
    "for v in data_df.values():\n",
    "    print(v.isnull().sum().sum(), len(v.columns), sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理中文片名()內含有2D、3D、imax(大小寫)的部分\n",
    "# 刪除現場XXXXX劇院現場的資料\n",
    "# 去重複\n",
    "pattern = r'\\([^()]*?(2D|3D|IMAX|.*版)[^()]*?\\)'\n",
    "for key, df in data_df.items():\n",
    "    df['中文片名'] = df['中文片名'].apply(lambda x: re.sub(pattern, '', x, flags=re.IGNORECASE))\n",
    "    df = df[~df['中文片名'].str.contains('劇院現場')].reset_index(drop=True)\n",
    "    data_df[key] = df.drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新增標籤\n",
    "---\n",
    "這個會爬很久很久，目前已爬完存出去了，應該不會再用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf = []\n",
    "errors = []\n",
    "for i,df in enumerate(data_df.values()):\n",
    "    new_column = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            new_column.append(genres(row['中文片名']))\n",
    "        except Exception as e:\n",
    "            print(\"Error occurred in row:\", index)\n",
    "            print(\"Error occurred in row:\", row['中文片名'], row['原文片名'])\n",
    "            print(\"Error message:\", str(e))\n",
    "            new_column.append(None)\n",
    "            errors.append((index, row['年度'], row['中文片名'], row['原文片名']))\n",
    "\n",
    "    df['類型'] = new_column\n",
    "    resultdf.append(df)\n",
    "    df.to_csv(f'output{i}.csv', index=False)\n",
    "    if errors:\n",
    "        with open(f'error{i}.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['index', '年度', '中文片名', '原文片名']) \n",
    "            writer.writerows(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Linebot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
